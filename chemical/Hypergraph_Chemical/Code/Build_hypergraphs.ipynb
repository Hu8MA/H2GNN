{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FcfPp1sPTei"
      },
      "source": [
        "#Here we use the K-12 output to generate a hypergraph; you can replace that with another K output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrHCHwRlXxym",
        "outputId": "6b2908fe-fc9f-4bac-9014-9106d05b259e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch pandas numpy\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Set, Tuple\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeA8PDLdXynF",
        "outputId": "e1f238fe-6682-42cf-8142-b299fe5235f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0kWa0y4X5oh"
      },
      "outputs": [],
      "source": [
        "def parse_segmented_kmers(segmented_string: str) -> List[str]:\n",
        "    # Split by semicolon and filter empty strings\n",
        "    kmers = [k.strip() for k in segmented_string.split(';') if k.strip()]\n",
        "    return kmers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owfK5NsVYHAe"
      },
      "outputs": [],
      "source": [
        "def build_drugbank_hypergraph(\n",
        "    csv_path: str,\n",
        "    k: int = 3,\n",
        "    save_dir: str = '/content/drive/MyDrive/MLHygnn/DB/hypergraphs/'\n",
        ") -> Tuple[torch.Tensor, Dict, Dict, Dict]:\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Building Hypergraph for DrugBank with k={k}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Loading data from: {csv_path}\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Loaded {len(df)} drugs\")\n",
        "\n",
        "    # Find k-mer column\n",
        "    kmer_col = None\n",
        "    for col in ['segmented_smile', 'Segmented_SMILE', 'kmers', 'Kmers']:\n",
        "        if col in df.columns:\n",
        "            kmer_col = col\n",
        "            break\n",
        "\n",
        "    if kmer_col is None:\n",
        "        raise ValueError(f\"No k-mer column found\")\n",
        "\n",
        "    print(f\"Using k-mer column: '{kmer_col}'\")\n",
        "\n",
        "    # Extract ALL k-mers\n",
        "    all_substructures = set()  # For vocabulary only\n",
        "    drug_substructures = {}     # Keep ALL k-mers per drug\n",
        "\n",
        "    print(\"Parsing pre-segmented k-mers...\")\n",
        "    for idx, row in df.iterrows():\n",
        "        if idx % 100 == 0:\n",
        "            print(f\"  Processing drug {idx+1}/{len(df)}...\", end='\\r')\n",
        "\n",
        "        drug_id = row['Drug_ID']\n",
        "        segmented_kmers = str(row[kmer_col])\n",
        "\n",
        "        # Parse k-mers\n",
        "        kmers = parse_segmented_kmers(segmented_kmers)\n",
        "\n",
        "        # KEEP ALL K-MERS (including duplicates) for this drug\n",
        "        drug_substructures[drug_id] = kmers  # Don't use set()!\n",
        "\n",
        "        # Add to vocabulary (unique only)\n",
        "        all_substructures.update(kmers)\n",
        "\n",
        "    print(f\"\\nParsing complete!\")\n",
        "\n",
        "    # Create mappings\n",
        "    node_to_idx = {sub: idx for idx, sub in enumerate(sorted(all_substructures))}\n",
        "    drug_to_idx = {drug_id: idx for idx, drug_id in enumerate(df['Drug_ID'])}\n",
        "\n",
        "    print(f\"  Unique substructures (nodes): {len(node_to_idx)}\")\n",
        "    print(f\"  Drugs (hyperedges): {len(drug_to_idx)}\")\n",
        "\n",
        "    # Build edge list (now with duplicates)\n",
        "    print(\"Building hypergraph edge list...\")\n",
        "    edge_list = []\n",
        "\n",
        "    for drug_id, substructures in drug_substructures.items():\n",
        "        edge_idx = drug_to_idx[drug_id]\n",
        "        # This will create multiple connections if same k-mer appears multiple times\n",
        "        for substructure in substructures:\n",
        "            node_idx = node_to_idx[substructure]\n",
        "            edge_list.append([node_idx, edge_idx])\n",
        "\n",
        "    edge_list_tensor = torch.tensor(edge_list, dtype=torch.long)\n",
        "    print(f\"Total connections created: {len(edge_list)}\")\n",
        "\n",
        "\n",
        "    # Save files\n",
        "    output_file = os.path.join(save_dir, f'hyG_drug_{len(df)}_kmer_{k}.pt')\n",
        "    torch.save(edge_list_tensor, output_file)\n",
        "    print(f\"\\nHypergraph saved to: {output_file}\")\n",
        "\n",
        "    metadata = {\n",
        "        'num_drugs': len(drug_to_idx),\n",
        "        'num_substructures': len(node_to_idx),\n",
        "        'num_connections': len(edge_list),\n",
        "        'k': k,\n",
        "        'drug_to_idx': drug_to_idx,\n",
        "        'node_to_idx': node_to_idx\n",
        "    }\n",
        "\n",
        "    metadata_file = os.path.join(save_dir, f'hyG_drug_{len(df)}_kmer_{k}_metadata.pt')\n",
        "    torch.save(metadata, metadata_file)\n",
        "\n",
        "    stats = {\n",
        "        'num_nodes': len(node_to_idx),\n",
        "        'num_edges': len(drug_to_idx),\n",
        "        'num_connections': len(edge_list),\n",
        "        'density': len(edge_list) / (len(node_to_idx) * len(drug_to_idx)),\n",
        "        'avg_substructures_per_drug': len(edge_list) / len(drug_to_idx),\n",
        "        'avg_drugs_per_substructure': len(edge_list) / len(node_to_idx)\n",
        "    }\n",
        "\n",
        "    print(\"\\nHypergraph Statistics:\")\n",
        "    for key, value in stats.items():\n",
        "        if 'num' in key:\n",
        "            print(f\"  {key}: {value:,}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    return edge_list_tensor, node_to_idx, drug_to_idx, stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVzHG5yFYJ1Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "def verify_hypergraph(file_path: str):\n",
        "    \"\"\"Verify saved hypergraph matches expected structure.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Verifying: {file_path}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return None\n",
        "\n",
        "    data = torch.load(file_path)\n",
        "\n",
        "    print(f\"Shape: {data.shape}\")\n",
        "    print(f\"First 10 rows:\\n{data[:10]}\")\n",
        "    print(f\"\\nUnique nodes: {len(torch.unique(data[:, 0]))}\")\n",
        "    print(f\"Unique drugs: {len(torch.unique(data[:, 1]))}\")\n",
        "    print(f\"Total connections: {data.shape[0]}\")\n",
        "\n",
        "    # Load metadata if available\n",
        "    metadata_path = file_path.replace('.pt', '_metadata.pt')\n",
        "    if os.path.exists(metadata_path):\n",
        "        metadata = torch.load(metadata_path)\n",
        "        print(f\"\\nMetadata:\")\n",
        "        print(f\"  k-mer size: {metadata.get('k')}\")\n",
        "        print(f\"  Avg k-mers/drug: {metadata.get('num_connections', 0) / metadata.get('num_drugs', 1):.2f}\")\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JJL02MFYOFO",
        "outputId": "565de511-adf9-407d-a9f9-a7f1196c5e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Building Hypergraph for DrugBank with k=12\n",
            "============================================================\n",
            "Loading data from: /content/drive/MyDrive/MLHygnn/DB/kmer_results_simple1709drugs/drugbank_kmers_k12.csv\n",
            "Loaded 1709 drugs\n",
            "Using k-mer column: 'Segmented_SMILE'\n",
            "Parsing pre-segmented k-mers...\n",
            "  Processing drug 1701/1709...\n",
            "Parsing complete!\n",
            "  Unique substructures (nodes): 43655\n",
            "  Drugs (hyperedges): 1709\n",
            "Building hypergraph edge list...\n",
            "Total connections created: 91615\n",
            "\n",
            "Hypergraph saved to: /content/drive/MyDrive/MLHygnn/DB/hypergraphs/hyG_drug_1709_kmer_12.pt\n",
            "\n",
            "Hypergraph Statistics:\n",
            "  num_nodes: 43,655\n",
            "  num_edges: 1,709\n",
            "  num_connections: 91,615\n",
            "  density: 0.0012\n",
            "  avg_substructures_per_drug: 53.6074\n",
            "  avg_drugs_per_substructure: 2.0986\n",
            "\n",
            "============================================================\n",
            "Verifying: /content/drive/MyDrive/MLHygnn/DB/hypergraphs/hyG_drug_1709_kmer_12.pt\n",
            "============================================================\n",
            "Shape: torch.Size([91615, 2])\n",
            "First 10 rows:\n",
            "tensor([[30933,     0],\n",
            "        [32283,     0],\n",
            "        [40042,     0],\n",
            "        [27117,     0],\n",
            "        [17936,     0],\n",
            "        [33099,     0],\n",
            "        [41421,     0],\n",
            "        [ 1827,     0],\n",
            "        [22762,     0],\n",
            "        [ 8248,     0]])\n",
            "\n",
            "Unique nodes: 43655\n",
            "Unique drugs: 1709\n",
            "Total connections: 91615\n",
            "\n",
            "Metadata:\n",
            "  k-mer size: 12\n",
            "  Avg k-mers/drug: 53.61\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Build hypergraph from pre-segmented k-mer file\n",
        "    edge_list, node_vocab, drug_vocab, stats = build_drugbank_hypergraph(\n",
        "        csv_path='/content/drive/MyDrive/MLHygnn/DB/kmer_results_simple1709drugs/drugbank_kmers_k12.csv',  # We use the semicolon-separated file\n",
        "        k=12\n",
        "    )\n",
        "\n",
        "    # Verify output\n",
        "    verify_hypergraph('/content/drive/MyDrive/MLHygnn/DB/hypergraphs/hyG_drug_1709_kmer_12.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
