{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2cqeaSC828p"
      },
      "source": [
        "This code groups each drug with all the interaction types it appears in.\n",
        "For every row in the dataset, the interaction label is added to both drugs in the pair.\n",
        "Then the interaction types for each drug are combined, duplicates are removed, and the final list is sorted and saved.\n",
        "The result is one row per drug showing all interaction types linked to that drug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "punXzY3-qswV",
        "outputId": "7127985b-4464-4723-a04e-1745b7630365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiPFve1pqn6W",
        "outputId": "a0f6fb57-d34e-4637-df61-ad32fa407bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing complete!\n",
            "Total unique drugs: 1709\n",
            "Output saved to: /content/drive/MyDrive/MLHygnn/DB/OutPutPreprosseing/drug_interaction_types.csv\n",
            "\n",
            "First 10 rows:\n",
            "   Drug_ID                                  Interaction_Types\n",
            "0  DB00006                           12;4;47;49;6;66;70;73;75\n",
            "1  DB00014                                     15;20;49;58;70\n",
            "2  DB00027                                           70;73;77\n",
            "3  DB00035                                              49;70\n",
            "4  DB00080                                              49;70\n",
            "5  DB00091  11;13;18;21;34;35;4;42;47;49;57;67;68;70;72;73...\n",
            "6  DB00104                    15;20;25;47;49;54;58;70;73;75;9\n",
            "7  DB00115                                              70;75\n",
            "8  DB00120                                              34;49\n",
            "9  DB00122                                              70;73\n",
            "\n",
            "Interaction type statistics:\n",
            "Min interaction types per drug: 1\n",
            "Max interaction types per drug: 25\n",
            "Average interaction types per drug: 7.89\n",
            "\n",
            "Example drug with multiple interaction types:\n",
            "Drug: DB00006\n",
            "Interaction types: 12;4;47;49;6;66;70;73;75\n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/drive/MyDrive/MLHygnn/DB/DDI_unique_interactionsAnalysis.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "drug1_interactions = defaultdict(set)\n",
        "drug2_interactions = defaultdict(set)\n",
        "\n",
        "# Process each row to collect interaction types for each drug\n",
        "for _, row in df.iterrows():\n",
        "    drug1 = row['Drug1_ID']\n",
        "    drug2 = row['Drug2_ID']\n",
        "    label = row['Label']\n",
        "\n",
        "    # Add interaction type to both drugs\n",
        "    drug1_interactions[drug1].add(label)\n",
        "    drug2_interactions[drug2].add(label)\n",
        "\n",
        "# Combine both dictionaries to get all drugs and their interaction types\n",
        "all_drug_interactions = defaultdict(set)\n",
        "\n",
        "# Add from drug1 interactions\n",
        "for drug, interactions in drug1_interactions.items():\n",
        "    all_drug_interactions[drug].update(interactions)\n",
        "\n",
        "# Add from drug2 interactions\n",
        "for drug, interactions in drug2_interactions.items():\n",
        "    all_drug_interactions[drug].update(interactions)\n",
        "\n",
        " # Create the final DataFrame with proper format\n",
        "result_data = []\n",
        "for drug_id, interaction_types in all_drug_interactions.items():\n",
        "    # Sort interaction types for consistency and join with semicolon\n",
        "    interactions_str = ';'.join(sorted(map(str, interaction_types)))\n",
        "    # Format as \"Drug_ID,Interaction_Types\" in one column initially\n",
        "    result_data.append([drug_id, interactions_str])\n",
        "\n",
        "# Create DataFrame with proper column names\n",
        "result_df = pd.DataFrame(result_data, columns=['Drug_ID', 'Interaction_Types'])\n",
        "result_df = result_df.sort_values('Drug_ID').reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "# Save to CSV\n",
        "output_path ='/content/drive/MyDrive/MLHygnn/DB/OutPutPreprosseing/drug_interaction_types.csv'\n",
        "result_df.to_csv(output_path, index=False,quoting=1)\n",
        "\n",
        "# Display summary information\n",
        "print(f\"Processing complete!\")\n",
        "print(f\"Total unique drugs: {len(result_df)}\")\n",
        "print(f\"Output saved to: {output_path}\")\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(result_df.head(10))\n",
        "\n",
        "# Display some statistics\n",
        "interaction_counts = result_df['Interaction_Types'].str.split(';').str.len()\n",
        "print(f\"\\nInteraction type statistics:\")\n",
        "print(f\"Min interaction types per drug: {interaction_counts.min()}\")\n",
        "print(f\"Max interaction types per drug: {interaction_counts.max()}\")\n",
        "print(f\"Average interaction types per drug: {interaction_counts.mean():.2f}\")\n",
        "\n",
        "# Show example of a drug with multiple interaction types\n",
        "multi_interaction_drug = result_df[interaction_counts > 1].iloc[0] if any(interaction_counts > 1) else None\n",
        "if multi_interaction_drug is not None:\n",
        "    print(f\"\\nExample drug with multiple interaction types:\")\n",
        "    print(f\"Drug: {multi_interaction_drug['Drug_ID']}\")\n",
        "    print(f\"Interaction types: {multi_interaction_drug['Interaction_Types']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRxDyLGz7zUU"
      },
      "source": [
        "# DATA VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFiOaGsDuHa9",
        "outputId": "7daad7ff-b2c7-459f-8647-55826a0f774c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DATA VALIDATION REPORT ===\n",
            "\n",
            "1. BASIC STATISTICS:\n",
            "Original file rows: 191877\n",
            "Original unique Drug1_IDs: 1599\n",
            "Original unique Drug2_IDs: 1639\n",
            "Total unique drugs in original: 1709\n",
            "Processed file rows: 1709\n",
            "Total unique drugs in processed: 1709\n",
            "\n",
            "2. DRUG COVERAGE:\n",
            "âœ… All drugs from original data are present in processed file\n",
            "âœ… No unexpected drugs in processed file\n",
            "\n",
            "3. INTERACTION ASSIGNMENT VALIDATION:\n",
            "âœ… All drug-interaction assignments match perfectly\n",
            "\n",
            "4. INTERACTION TYPES COVERAGE:\n",
            "Original interaction types: 86 ([np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(81), np.int64(82), np.int64(83), np.int64(84), np.int64(85), np.int64(86)])\n",
            "Processed interaction types: 86 ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86])\n",
            "âœ… All interaction types preserved\n",
            "âœ… No unexpected interaction types\n",
            "\n",
            "5. SAMPLE VERIFICATION:\n",
            "Drug DB01150:\n",
            "  Original: [70]\n",
            "  Processed: [70]\n",
            "  Match: âœ…\n",
            "Drug DB01330:\n",
            "  Original: [6, 49, 70, 73]\n",
            "  Processed: [6, 49, 70, 73]\n",
            "  Match: âœ…\n",
            "Drug DB00634:\n",
            "  Original: [49, 70]\n",
            "  Processed: [49, 70]\n",
            "  Match: âœ…\n",
            "\n",
            "=== SUMMARY ===\n",
            "ðŸŽ‰ VALIDATION PASSED: Data transformation is perfect!\n",
            "   - All drugs preserved\n",
            "   - All interactions correctly assigned\n",
            "   - All interaction types maintained\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Load both files\n",
        "original_file = '/content/drive/MyDrive/MLHygnn/DB/DDI_unique_interactionsAnalysis.csv'\n",
        "processed_file ='/content/drive/MyDrive/MLHygnn/DB/OutPutPreprosseing/drug_interaction_types.csv'\n",
        "original_df = pd.read_csv(original_file)\n",
        "processed_df = pd.read_csv(processed_file)\n",
        "\n",
        "print(\"=== DATA VALIDATION REPORT ===\\n\")\n",
        "\n",
        "# 1. Basic statistics comparison\n",
        "print(\"1. BASIC STATISTICS:\")\n",
        "print(f\"Original file rows: {len(original_df)}\")\n",
        "print(f\"Original unique Drug1_IDs: {original_df['Drug1_ID'].nunique()}\")\n",
        "print(f\"Original unique Drug2_IDs: {original_df['Drug2_ID'].nunique()}\")\n",
        "\n",
        "# Get all unique drugs from original data\n",
        "original_drugs = set(original_df['Drug1_ID']).union(set(original_df['Drug2_ID']))\n",
        "print(f\"Total unique drugs in original: {len(original_drugs)}\")\n",
        "\n",
        "print(f\"Processed file rows: {len(processed_df)}\")\n",
        "processed_drugs = set(processed_df['Drug_ID'])\n",
        "print(f\"Total unique drugs in processed: {len(processed_drugs)}\")\n",
        "\n",
        "# 2. Check for missing drugs\n",
        "missing_drugs = original_drugs - processed_drugs\n",
        "extra_drugs = processed_drugs - original_drugs\n",
        "\n",
        "print(f\"\\n2. DRUG COVERAGE:\")\n",
        "if missing_drugs:\n",
        "    print(f\"Missing drugs in processed file: {len(missing_drugs)}\")\n",
        "    print(f\"First 5 missing: {list(missing_drugs)[:5]}\")\n",
        "else:\n",
        "    print(\"All drugs from original data are present in processed file\")\n",
        "\n",
        "if extra_drugs:\n",
        "    print(f\" Extra drugs in processed file: {len(extra_drugs)}\")\n",
        "    print(f\"First 5 extra: {list(extra_drugs)[:5]}\")\n",
        "else:\n",
        "    print(\"No unexpected drugs in processed file\")\n",
        "\n",
        "# 3. Rebuild the drug-interaction mapping from original data\n",
        "original_drug_interactions = defaultdict(set)\n",
        "for _, row in original_df.iterrows():\n",
        "    drug1 = row['Drug1_ID']\n",
        "    drug2 = row['Drug2_ID']\n",
        "    label = row['Label']\n",
        "\n",
        "    original_drug_interactions[drug1].add(label)\n",
        "    original_drug_interactions[drug2].add(label)\n",
        "\n",
        "# 4. Parse processed data back to sets for comparison\n",
        "processed_drug_interactions = {}\n",
        "for _, row in processed_df.iterrows():\n",
        "    drug_id = row['Drug_ID']\n",
        "    interactions_str = str(row['Interaction_Types'])\n",
        "\n",
        "    if pd.isna(row['Interaction_Types']) or interactions_str == 'nan':\n",
        "        interactions_set = set()\n",
        "    else:\n",
        "        # Convert to integers for proper comparison\n",
        "        interactions_set = set(map(int, interactions_str.split(';')))\n",
        "\n",
        "    processed_drug_interactions[drug_id] = interactions_set\n",
        "\n",
        "# 5. Compare interaction assignments for each drug\n",
        "print(f\"\\n3. INTERACTION ASSIGNMENT VALIDATION:\")\n",
        "mismatches = []\n",
        "total_interactions_original = 0\n",
        "total_interactions_processed = 0\n",
        "\n",
        "for drug in original_drugs:\n",
        "    original_set = original_drug_interactions[drug]\n",
        "    processed_set = processed_drug_interactions.get(drug, set())\n",
        "\n",
        "    total_interactions_original += len(original_set)\n",
        "    total_interactions_processed += len(processed_set)\n",
        "\n",
        "    if original_set != processed_set:\n",
        "        missing_in_processed = original_set - processed_set\n",
        "        extra_in_processed = processed_set - original_set\n",
        "        mismatches.append({\n",
        "            'drug': drug,\n",
        "            'missing': missing_in_processed,\n",
        "            'extra': extra_in_processed,\n",
        "            'original_count': len(original_set),\n",
        "            'processed_count': len(processed_set)\n",
        "        })\n",
        "\n",
        "if mismatches:\n",
        "    print(f\"  Found {len(mismatches)} drugs with interaction mismatches\")\n",
        "    print(\"First 5 mismatches:\")\n",
        "    for i, mismatch in enumerate(mismatches[:5]):\n",
        "        print(f\"  Drug {mismatch['drug']}:\")\n",
        "        print(f\"    Original: {len(mismatch['original_count'])} interactions\")\n",
        "        print(f\"    Processed: {len(mismatch['processed_count'])} interactions\")\n",
        "        if mismatch['missing']:\n",
        "            print(f\"    Missing: {mismatch['missing']}\")\n",
        "        if mismatch['extra']:\n",
        "            print(f\"    Extra: {mismatch['extra']}\")\n",
        "else:\n",
        "    print(\" All drug-interaction assignments match perfectly\")\n",
        "\n",
        "# 6. Interaction type coverage\n",
        "original_labels = set(original_df['Label'].unique())\n",
        "all_processed_labels = set()\n",
        "for interactions in processed_drug_interactions.values():\n",
        "    all_processed_labels.update(interactions)\n",
        "\n",
        "print(f\"\\n4. INTERACTION TYPES COVERAGE:\")\n",
        "print(f\"Original interaction types: {len(original_labels)} ({sorted(original_labels)})\")\n",
        "print(f\"Processed interaction types: {len(all_processed_labels)} ({sorted(all_processed_labels)})\")\n",
        "\n",
        "missing_labels = original_labels - all_processed_labels\n",
        "extra_labels = all_processed_labels - original_labels\n",
        "\n",
        "if missing_labels:\n",
        "    print(f\"  Missing interaction types: {missing_labels}\")\n",
        "else:\n",
        "    print(\" All interaction types preserved\")\n",
        "\n",
        "if extra_labels:\n",
        "    print(f\"  Extra interaction types: {extra_labels}\")\n",
        "else:\n",
        "    print(\" No unexpected interaction types\")\n",
        "\n",
        "# 7. Sample verification\n",
        "print(f\"\\n5. SAMPLE VERIFICATION:\")\n",
        "sample_drugs = list(original_drugs)[:3]\n",
        "for drug in sample_drugs:\n",
        "    orig_interactions = sorted(original_drug_interactions[drug])\n",
        "    proc_interactions = sorted(processed_drug_interactions.get(drug, set()))\n",
        "    print(f\"Drug {drug}:\")\n",
        "    print(f\"  Original: {orig_interactions}\")\n",
        "    print(f\"  Processed: {proc_interactions}\")\n",
        "    print(f\"  Match: {'Yes' if orig_interactions == proc_interactions else 'No'}\")\n",
        "\n",
        "# 8. Summary\n",
        "print(f\"\\n=== SUMMARY ===\")\n",
        "if not missing_drugs and not extra_drugs and not mismatches and not missing_labels and not extra_labels:\n",
        "    print(\"VALIDATION PASSED: Data transformation is perfect!\")\n",
        "    print(\"   - All drugs preserved\")\n",
        "    print(\"   - All interactions correctly assigned\")\n",
        "    print(\"   - All interaction types maintained\")\n",
        "else:\n",
        "    print(\" VALIDATION ISSUES DETECTED:\")\n",
        "    if missing_drugs:\n",
        "        print(f\"   - {len(missing_drugs)} drugs missing\")\n",
        "    if extra_drugs:\n",
        "        print(f\"   - {len(extra_drugs)} unexpected drugs\")\n",
        "    if mismatches:\n",
        "        print(f\"   - {len(mismatches)} drugs with incorrect interactions\")\n",
        "    if missing_labels or extra_labels:\n",
        "        print(f\"   - Interaction type inconsistencies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPd6WKZc74BO"
      },
      "source": [
        "# Summary typer-interaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwU7noUhvhrG",
        "outputId": "f71dfcc1-a3ff-4a56-c895-5480483bdf36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analysis saved to: /content/drive/MyDrive/MLHygnn/DB/OutPutPreprosseing/summarytyperinter.csv\n",
            "Rows saved: 86\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the data files\n",
        "original_file = '/content/drive/MyDrive/MLHygnn/DB/DDI_unique_interactionsAnalysis.csv'\n",
        "processed_file = '/content/drive/MyDrive/MLHygnn/DB/OutPutPreprosseing/drug_interaction_types.csv'\n",
        "\n",
        "original_df = pd.read_csv(original_file)\n",
        "processed_df = pd.read_csv(processed_file)\n",
        "\n",
        "# Analysis from original data (interaction frequency)\n",
        "interaction_counts = original_df['Label'].value_counts().sort_index()\n",
        "total_interactions = len(original_df)\n",
        "\n",
        "# Analysis from processed data (unique drugs per interaction type)\n",
        "interaction_drug_count = defaultdict(set)\n",
        "\n",
        "for _, row in processed_df.iterrows():\n",
        "    drug_id = row['Drug_ID']\n",
        "    interactions_str = str(row['Interaction_Types'])\n",
        "\n",
        "    if pd.notna(row['Interaction_Types']) and interactions_str != 'nan':\n",
        "        interaction_types = list(map(int, interactions_str.split(';')))\n",
        "        for interaction_type in interaction_types:\n",
        "            interaction_drug_count[interaction_type].add(drug_id)\n",
        "\n",
        "# Convert to counts\n",
        "drug_counts_per_type = {k: len(v) for k, v in interaction_drug_count.items()}\n",
        "\n",
        "# Main analysis CSV\n",
        "analysis_data = []\n",
        "for interaction_type in sorted(interaction_counts.index):\n",
        "    interactions = interaction_counts[interaction_type]\n",
        "    unique_drugs = drug_counts_per_type.get(interaction_type, 0)\n",
        "    avg_per_drug = interactions / unique_drugs if unique_drugs > 0 else 0\n",
        "    percentage = (interactions / total_interactions) * 100\n",
        "\n",
        "    analysis_data.append({\n",
        "        'Interaction_Type_ID': interaction_type,\n",
        "        'Total_Interactions': interactions,\n",
        "        'Unique_Drugs': unique_drugs,\n",
        "        'Avg_Interactions_Per_Drug': round(avg_per_drug, 2),\n",
        "        'Percentage_of_Total': round(percentage, 2)\n",
        "    })\n",
        "\n",
        "analysis_df = pd.DataFrame(analysis_data)\n",
        "analysis_output = '/content/drive/MyDrive/MLHygnn/DB/OutPutPreprosseing/summarytyperinter.csv'\n",
        "analysis_df.to_csv(analysis_output, index=False)\n",
        "\n",
        "print(f\"Analysis saved to: {analysis_output}\")\n",
        "print(f\"Rows saved: {len(analysis_df)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
