{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-i9vrxtvWly",
        "outputId": "2504b91e-9603-42fb-e29d-03e584a7c9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Installation complete\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit -q\n",
        "print(\"âœ… Installation complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeL7DASZvY50"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from rdkit.Chem import rdMolDescriptors\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from rdkit import RDLogger\n",
        "from scipy.sparse import vstack, csr_matrix\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score,\n",
        "    accuracy_score, f1_score, precision_score, recall_score\n",
        ")\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI292uHzvaN1",
        "outputId": "7173d94b-3b79-4fdc-8ae3-2019c2607b66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwvOB9cXvgwn",
        "outputId": "ea8104d0-47fc-42e1-be44-aa8756000acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Config loaded\n",
            "âœ… Data loaded: 153501 train+, 153501 train-, 19189 test+, 19189 test-\n"
          ]
        }
      ],
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/MLHygnn/BaseLine/RandomForest_Chemical/'\n",
        "SMILES_FILE = '/content/drive/MyDrive/MLHygnn/BaseLine/Drugs_with_Smiles.csv'\n",
        "\n",
        "config = {\n",
        "    'n_estimators': 500,\n",
        "    'max_depth': 20,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "print(\"âœ… Config loaded\")\n",
        "\n",
        "train_pos = pd.read_csv(f'{BASE_PATH}data/train_postive.csv')\n",
        "train_neg = pd.read_csv(f'{BASE_PATH}data/train_negatives.csv')\n",
        "test_pos = pd.read_csv(f'{BASE_PATH}data/test_postive.csv')\n",
        "test_neg = pd.read_csv(f'{BASE_PATH}data/test_negatives.csv')\n",
        "\n",
        "smiles_df = pd.read_csv(SMILES_FILE)\n",
        "smiles_dict = dict(zip(smiles_df['DrugBank_ID'], smiles_df['SMILES']))\n",
        "\n",
        "print(f\"âœ… Data loaded: {len(train_pos)} train+, {len(train_neg)} train-, {len(test_pos)} test+, {len(test_neg)} test-\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We use Morgan Fingerprint (2, 2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61W-Xo3rvoTw",
        "outputId": "26ed1623-2bef-4f77-8c6d-1aa4ab3818c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-computing fingerprints for all drugs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing fingerprints: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1709/1709 [00:02<00:00, 770.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Pre-computed 1709 drug fingerprints\n",
            "\n",
            "Preparing training data (sparse)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train positive: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153501/153501 [00:42<00:00, 3625.18it/s]\n",
            "Train negative: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153501/153501 [00:42<00:00, 3583.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Training data ready: (307002, 4096)\n",
            "   Sparsity: 97.84%\n",
            "   Memory saved: ~97.8%\n",
            "\n",
            "Preparing test data (sparse)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test positive: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19189/19189 [00:05<00:00, 3277.20it/s]\n",
            "Test negative: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19189/19189 [00:04<00:00, 4118.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Test data ready: (38378, 4096)\n",
            "   Sparsity: 97.82%\n",
            "\n",
            "ðŸ“Š Memory Usage:\n",
            "   Training data: 312.59 MB\n",
            "   Test data: 39.28 MB\n",
            "   Total: 351.87 MB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Suppress warnings\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# DEFINE FUNCTIONS\n",
        "def smiles_to_fp(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return np.zeros(2048)\n",
        "    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2, 2048))\n",
        "\n",
        "\n",
        "# PRE-COMPUTE FINGERPRINTS (assumes smiles_dict exists)\n",
        "print(\"Pre-computing fingerprints for all drugs...\")\n",
        "drug_fps = {}\n",
        "for drug_id, smiles in tqdm(smiles_dict.items(), desc=\"Computing fingerprints\"):\n",
        "    drug_fps[drug_id] = smiles_to_fp(smiles)\n",
        "print(f\"âœ… Pre-computed {len(drug_fps)} drug fingerprints\")\n",
        "\n",
        "# DEFINE FAST PAIR FUNCTION\n",
        "def pair_features_fast(drug1, drug2):\n",
        "    fp1 = drug_fps.get(drug1, np.zeros(2048))\n",
        "    fp2 = drug_fps.get(drug2, np.zeros(2048))\n",
        "    return np.concatenate([fp1, fp2])\n",
        "\n",
        "# PREPARE TRAINING DATA - SPARSE\n",
        "# \n",
        "print(\"\\nPreparing training data (sparse)...\")\n",
        "X_train_list = []\n",
        "y_train = []\n",
        "\n",
        "for _, row in tqdm(train_pos.iterrows(), total=len(train_pos), desc=\"Train positive\"):\n",
        "    fp = pair_features_fast(row['Drug1_ID'], row['Drug2_ID'])\n",
        "    X_train_list.append(csr_matrix(fp))  # Convert to sparse\n",
        "    y_train.append(1)\n",
        "\n",
        "for _, row in tqdm(train_neg.iterrows(), total=len(train_neg), desc=\"Train negative\"):\n",
        "    fp = pair_features_fast(row['Drug1_ID'], row['Drug2_ID'])\n",
        "    X_train_list.append(csr_matrix(fp))\n",
        "    y_train.append(0)\n",
        "\n",
        "X_train = vstack(X_train_list)  # Combine into sparse matrix\n",
        "y_train = np.array(y_train)\n",
        "print(f\"âœ… Training data ready: {X_train.shape}\")\n",
        "print(f\"   Sparsity: {1 - X_train.nnz / np.prod(X_train.shape):.2%}\")\n",
        "print(f\"   Memory saved: ~{(1 - X_train.nnz / np.prod(X_train.shape)) * 100:.1f}%\")\n",
        "\n",
        "# PREPARE TEST DATA - SPARSE\n",
        "print(\"\\nPreparing test data (sparse)...\")\n",
        "X_test_list = []\n",
        "y_test = []\n",
        "\n",
        "for _, row in tqdm(test_pos.iterrows(), total=len(test_pos), desc=\"Test positive\"):\n",
        "    fp = pair_features_fast(row['Drug1_ID'], row['Drug2_ID'])\n",
        "    X_test_list.append(csr_matrix(fp))\n",
        "    y_test.append(1)\n",
        "\n",
        "for _, row in tqdm(test_neg.iterrows(), total=len(test_neg), desc=\"Test negative\"):\n",
        "    fp = pair_features_fast(row['Drug1_ID'], row['Drug2_ID'])\n",
        "    X_test_list.append(csr_matrix(fp))\n",
        "    y_test.append(0)\n",
        "\n",
        "X_test = vstack(X_test_list)\n",
        "y_test = np.array(y_test)\n",
        "print(f\"âœ… Test data ready: {X_test.shape}\")\n",
        "print(f\"   Sparsity: {1 - X_test.nnz / np.prod(X_test.shape):.2%}\")\n",
        "\n",
        "# MEMORY CHECK\n",
        "import sys\n",
        "train_size_mb = (X_train.data.nbytes + X_train.indices.nbytes + X_train.indptr.nbytes) / (1024**2)\n",
        "test_size_mb = (X_test.data.nbytes + X_test.indices.nbytes + X_test.indptr.nbytes) / (1024**2)\n",
        "print(f\"\\nðŸ“Š Memory Usage:\")\n",
        "print(f\"   Training data: {train_size_mb:.2f} MB\")\n",
        "print(f\"   Test data: {test_size_mb:.2f} MB\")\n",
        "print(f\"   Total: {train_size_mb + test_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvs_vwipvRt0",
        "outputId": "37405f64-05a5-4817-c70b-0f20f0ccb76f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING RANDOM FOREST\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 26.3min\n",
            "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 29.4min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Training complete: 29.37 minutes\n",
            "\n",
            "================================================================================\n",
            "TESTING\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    6.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    5.4s finished\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING RANDOM FOREST\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=config['n_estimators'],\n",
        "    max_depth=config['max_depth'],\n",
        "    random_state=config['random_state'],\n",
        "    n_jobs=-1,  # Change to n_jobs=1 for single-core training\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "rf.fit(X_train, y_train)\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "print(f\"âœ… Training complete: {train_time/60:.2f} minutes\")\n",
        "\n",
        "# TEST MODEL\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TESTING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "pr_auc = average_precision_score(y_test, y_pred_proba)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zzqSrk0vumA",
        "outputId": "9667a91e-a183-45b9-ebab-948452558de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RANDOM FOREST - FINAL RESULTS\n",
            "================================================================================\n",
            "Accuracy:  0.7853\n",
            "Precision: 0.7546\n",
            "Recall:    0.8456\n",
            "F1-Score:  0.7975\n",
            "ROC-AUC:   0.8752\n",
            "PR-AUC:    0.8779\n",
            "\n",
            "Training Time: 29.37 minutes\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# PRINT RESULTS\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RANDOM FOREST - FINAL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "print(f\"PR-AUC:    {pr_auc:.4f}\")\n",
        "print(f\"\\nTraining Time: {train_time/60:.2f} minutes\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
