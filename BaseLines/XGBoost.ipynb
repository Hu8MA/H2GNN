{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_cell",
        "outputId": "465115cb-18f4-4486-9a1b-8c45864854c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Installation complete\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit xgboost -q\n",
        "print(\"‚úÖ Installation complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imports",
        "outputId": "e9862f12-306c-41f1-c28d-87d2e1f8b1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Imports complete\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import xgboost as xgb\n",
        "from rdkit import RDLogger\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# Suppress warnings\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Imports complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mount_cell",
        "outputId": "91b85c03-0959-497b-cc9d-5beb9647fab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        " # CONFIGURATION\n",
        "BASE_PATH = '/content/drive/MyDrive/XGBoost/'\n",
        "SMILES_FILE = '/content/drive/MyDrive/XGBoost/Drugs_with_Smiles.csv'\n",
        "\n",
        "# XGBoost Configuration (Matching HGNN)\n",
        "config = {\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.005,  # Same as HGNN\n",
        "    'n_estimators': 200,\n",
        "    'tree_method': 'hist',  # Fast histogram-based algorithm\n",
        "    'device': 'cpu',\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1  # Use all CPU cores\n",
        "}\n",
        "\n",
        "print(\"Configuration loaded\")\n",
        "print(f\"   Base path: {BASE_PATH}\")\n",
        "print(f\"   Device: {config['device']} (matching HGNN)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "load_data",
        "outputId": "d5374eaf-7f88-448b-ad1d-c9c8e42bbb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING DATA\n",
            "================================================================================\n",
            "Data loaded:\n",
            "   Training samples: 153,489\n",
            "   Validation samples: 19,188\n",
            "   Test samples: 19,200\n",
            "   Unique drugs: 1,709\n",
            "   Interaction types: 86 (classes 0-85)\n",
            "\n",
            "Training set class distribution:\n",
            "   Min samples per class: 4\n",
            "   Max samples per class: 48746\n",
            "   Mean samples per class: 1784.8\n",
            "   Median samples per class: 227.5\n"
          ]
        }
      ],
      "source": [
        "# LOAD DATA\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load train/val/test splits\n",
        "train_df = pd.read_csv(f'{BASE_PATH}data/train_positive.csv')\n",
        "val_df = pd.read_csv(f'{BASE_PATH}data/val_positive.csv')\n",
        "test_df = pd.read_csv(f'{BASE_PATH}data/test_positive.csv')\n",
        "\n",
        "# Load SMILES\n",
        "smiles_df = pd.read_csv(SMILES_FILE)\n",
        "smiles_dict = dict(zip(smiles_df['DrugBank_ID'], smiles_df['SMILES']))\n",
        "\n",
        "print(f\"Data loaded:\")\n",
        "print(f\"   Training samples: {len(train_df):,}\")\n",
        "print(f\"   Validation samples: {len(val_df):,}\")\n",
        "print(f\"   Test samples: {len(test_df):,}\")\n",
        "print(f\"   Unique drugs: {len(smiles_dict):,}\")\n",
        "print(f\"   Interaction types: {train_df['Label'].nunique()} (classes 0-85)\")\n",
        "\n",
        "# Check class distribution\n",
        "print(f\"\\nTraining set class distribution:\")\n",
        "class_counts = train_df['Label'].value_counts().sort_index()\n",
        "print(f\"   Min samples per class: {class_counts.min()}\")\n",
        "print(f\"   Max samples per class: {class_counts.max()}\")\n",
        "print(f\"   Mean samples per class: {class_counts.mean():.1f}\")\n",
        "print(f\"   Median samples per class: {class_counts.median():.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We use Morgan Fingerprint (2, 2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fingerprints",
        "outputId": "e0a0b2eb-abe3-422a-b4e3-7125a91ce457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPUTING MORGAN FINGERPRINTS\n",
            "================================================================================\n",
            "Pre-computing fingerprints for all drugs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing fingerprints: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1709/1709 [00:02<00:00, 750.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-computed 1709 drug fingerprints\n",
            "Failed to parse 1 SMILES\n",
            "\n",
            "Fingerprint statistics:\n",
            "   Fingerprint size: 2048 bits\n",
            "   Average density: 2.15%\n",
            "   Pair feature size: 4096 dimensions\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# COMPUTE DRUG FINGERPRINTS\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPUTING MORGAN FINGERPRINTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def smiles_to_fingerprint(smiles, radius=2, n_bits=2048):\n",
        "    \"\"\"Convert SMILES to Morgan fingerprint\"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return np.zeros(n_bits)\n",
        "    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, radius, n_bits))\n",
        "\n",
        "# Pre-compute all drug fingerprints\n",
        "print(\"Pre-computing fingerprints for all drugs...\")\n",
        "drug_fps = {}\n",
        "failed_drugs = []\n",
        "\n",
        "for drug_id, smiles in tqdm(smiles_dict.items(), desc=\"Computing fingerprints\"):\n",
        "    fp = smiles_to_fingerprint(smiles)\n",
        "    if fp.sum() == 0:  # Failed to parse\n",
        "        failed_drugs.append(drug_id)\n",
        "    drug_fps[drug_id] = fp\n",
        "\n",
        "print(f\"Pre-computed {len(drug_fps)} drug fingerprints\")\n",
        "if failed_drugs:\n",
        "    print(f\"Failed to parse {len(failed_drugs)} SMILES\")\n",
        "\n",
        "print(f\"\\nFingerprint statistics:\")\n",
        "fp_densities = [fp.sum() / len(fp) for fp in drug_fps.values()]\n",
        "print(f\"   Fingerprint size: 2048 bits\")\n",
        "print(f\"   Average density: {np.mean(fp_densities):.2%}\")\n",
        "print(f\"   Pair feature size: {2048 * 2} dimensions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prepare_data",
        "outputId": "8d67cd05-a6cd-4f1f-8460-c89451266a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PREPARING DATASETS\n",
            "================================================================================\n",
            "\n",
            "Preparing training data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 153489/153489 [00:10<00:00, 14548.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing validation data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19188/19188 [00:00<00:00, 21537.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing test data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19200/19200 [00:00<00:00, 21406.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Data preparation complete:\n",
            "   X_train shape: (153489, 4096)\n",
            "   X_val shape: (19188, 4096)\n",
            "   X_test shape: (19200, 4096)\n",
            "   Number of classes: 86\n",
            "\n",
            "Memory usage:\n",
            "   Training: 4796.53 MB\n",
            "   Validation: 599.62 MB\n",
            "   Test: 600.00 MB\n",
            "   Total: 5996.16 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREPARING DATASETS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def prepare_data(df, drug_fps, desc=\"Processing\"):\n",
        "    \"\"\"Convert drug pairs to concatenated fingerprints\"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df), desc=desc):\n",
        "        drug1_fp = drug_fps.get(row['Drug1_ID'], np.zeros(2048))\n",
        "        drug2_fp = drug_fps.get(row['Drug2_ID'], np.zeros(2048))\n",
        "\n",
        "        # Concatenate features\n",
        "        pair_features = np.concatenate([drug1_fp, drug2_fp])\n",
        "\n",
        "        X.append(pair_features)\n",
        "        y.append(row['Label'])  # Interaction type (0-85)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Prepare all datasets\n",
        "print(\"\\nPreparing training data...\")\n",
        "X_train, y_train = prepare_data(train_df, drug_fps, \"Train\")\n",
        "\n",
        "print(\"\\nPreparing validation data...\")\n",
        "X_val, y_val = prepare_data(val_df, drug_fps, \"Validation\")\n",
        "\n",
        "print(\"\\nPreparing test data...\")\n",
        "X_test, y_test = prepare_data(test_df, drug_fps, \"Test\")\n",
        "y_train = y_train - 1  # Convert 1-86 to 0-85\n",
        "y_val = y_val - 1\n",
        "y_test = y_test - 1\n",
        "print(f\"\\nData preparation complete:\")\n",
        "print(f\"   X_train shape: {X_train.shape}\")\n",
        "print(f\"   X_val shape: {X_val.shape}\")\n",
        "print(f\"   X_test shape: {X_test.shape}\")\n",
        "print(f\"   Number of classes: {len(np.unique(y_train))}\")\n",
        "\n",
        "# Memory usage\n",
        "train_size_mb = X_train.nbytes / (1024**2)\n",
        "val_size_mb = X_val.nbytes / (1024**2)\n",
        "test_size_mb = X_test.nbytes / (1024**2)\n",
        "print(f\"\\nMemory usage:\")\n",
        "print(f\"   Training: {train_size_mb:.2f} MB\")\n",
        "print(f\"   Validation: {val_size_mb:.2f} MB\")\n",
        "print(f\"   Test: {test_size_mb:.2f} MB\")\n",
        "print(f\"   Total: {train_size_mb + val_size_mb + test_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We use class weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "class_weights",
        "outputId": "f74ccfc9-1b9c-4405-e096-8a34657bc2af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "CALCULATING CLASS WEIGHTS\n",
            "================================================================================\n",
            "\n",
            "Class weight statistics:\n",
            "   Alpha parameter: 0.3\n",
            "   Min weight: 0.1566\n",
            "   Max weight: 2.6340\n",
            "   Mean weight: 1.0000\n",
            "\n",
            "Sample distribution:\n",
            "   Min samples: 4\n",
            "   Max samples: 48746\n",
            "   Mean samples: 1784.8\n",
            "   Imbalance ratio: 12186.5x\n",
            "\n",
            "Sample weights prepared for 153,489 training samples\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CALCULATING CLASS WEIGHTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Count samples per class\n",
        "type_counts = np.bincount(y_train, minlength=86)\n",
        "\n",
        "# Calculate weights using same formula as HGNN\n",
        "alpha = 0.3  # Same as HGNN\n",
        "class_weights = 1.0 / np.power(np.maximum(type_counts, 1), alpha)\n",
        "class_weights = class_weights / class_weights.mean()\n",
        "\n",
        "print(f\"\\nClass weight statistics:\")\n",
        "print(f\"   Alpha parameter: {alpha}\")\n",
        "print(f\"   Min weight: {class_weights.min():.4f}\")\n",
        "print(f\"   Max weight: {class_weights.max():.4f}\")\n",
        "print(f\"   Mean weight: {class_weights.mean():.4f}\")\n",
        "print(f\"\\nSample distribution:\")\n",
        "print(f\"   Min samples: {type_counts.min()}\")\n",
        "print(f\"   Max samples: {type_counts.max()}\")\n",
        "print(f\"   Mean samples: {type_counts.mean():.1f}\")\n",
        "print(f\"   Imbalance ratio: {type_counts.max() / max(type_counts.min(), 1):.1f}x\")\n",
        "\n",
        "# Convert to sample weights for XGBoost\n",
        "sample_weights = class_weights[y_train]\n",
        "print(f\"\\nSample weights prepared for {len(sample_weights):,} training samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "train_model",
        "outputId": "3842ce44-65d3-43b7-c3aa-9b769d4304b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING XGBOOST MODEL (UNWEIGHTED)\n",
            "================================================================================\n",
            "\n",
            "Configuration:\n",
            "   max_depth: 8\n",
            "   learning_rate: 0.005\n",
            "   n_estimators: 200\n",
            "   tree_method: hist\n",
            "   device: cpu\n",
            "   random_state: 42\n",
            "   n_jobs: -1\n",
            "\n",
            "Training configuration:\n",
            "   Training on: X_train only (153,489 samples)\n",
            "   Monitoring on: X_val (19,188 samples) - for progress tracking only\n",
            "   Final evaluation: X_test (19,200 samples)\n",
            "   Sample weighting: None (unweighted training)\n",
            "\n",
            "Starting training with 200 trees...\n",
            "[0]\tvalidation_0-mlogloss:4.24837\n",
            "[1]\tvalidation_0-mlogloss:4.19273\n",
            "[2]\tvalidation_0-mlogloss:4.14114\n",
            "[3]\tvalidation_0-mlogloss:4.09306\n",
            "[4]\tvalidation_0-mlogloss:4.04754\n",
            "[5]\tvalidation_0-mlogloss:4.00444\n",
            "[6]\tvalidation_0-mlogloss:3.96362\n",
            "[7]\tvalidation_0-mlogloss:3.92399\n",
            "[8]\tvalidation_0-mlogloss:3.88647\n",
            "[9]\tvalidation_0-mlogloss:3.85083\n",
            "[10]\tvalidation_0-mlogloss:3.81604\n",
            "[11]\tvalidation_0-mlogloss:3.78304\n",
            "[12]\tvalidation_0-mlogloss:3.74932\n",
            "[13]\tvalidation_0-mlogloss:3.71716\n",
            "[14]\tvalidation_0-mlogloss:3.68734\n",
            "[15]\tvalidation_0-mlogloss:3.65761\n",
            "[16]\tvalidation_0-mlogloss:3.62874\n",
            "[17]\tvalidation_0-mlogloss:3.60094\n",
            "[18]\tvalidation_0-mlogloss:3.57374\n",
            "[19]\tvalidation_0-mlogloss:3.54833\n",
            "[20]\tvalidation_0-mlogloss:3.52288\n",
            "[21]\tvalidation_0-mlogloss:3.49796\n",
            "[22]\tvalidation_0-mlogloss:3.47313\n",
            "[23]\tvalidation_0-mlogloss:3.44987\n",
            "[24]\tvalidation_0-mlogloss:3.42644\n",
            "[25]\tvalidation_0-mlogloss:3.40416\n",
            "[26]\tvalidation_0-mlogloss:3.38212\n",
            "[27]\tvalidation_0-mlogloss:3.36103\n",
            "[28]\tvalidation_0-mlogloss:3.33983\n",
            "[29]\tvalidation_0-mlogloss:3.31924\n",
            "[30]\tvalidation_0-mlogloss:3.29835\n",
            "[31]\tvalidation_0-mlogloss:3.27851\n",
            "[32]\tvalidation_0-mlogloss:3.25909\n",
            "[33]\tvalidation_0-mlogloss:3.24019\n",
            "[34]\tvalidation_0-mlogloss:3.22120\n",
            "[35]\tvalidation_0-mlogloss:3.20315\n",
            "[36]\tvalidation_0-mlogloss:3.18547\n",
            "[37]\tvalidation_0-mlogloss:3.16815\n",
            "[38]\tvalidation_0-mlogloss:3.15061\n",
            "[39]\tvalidation_0-mlogloss:3.13363\n",
            "[40]\tvalidation_0-mlogloss:3.11699\n",
            "[41]\tvalidation_0-mlogloss:3.10054\n",
            "[42]\tvalidation_0-mlogloss:3.08443\n",
            "[43]\tvalidation_0-mlogloss:3.06836\n",
            "[44]\tvalidation_0-mlogloss:3.05236\n",
            "[45]\tvalidation_0-mlogloss:3.03697\n",
            "[46]\tvalidation_0-mlogloss:3.02179\n",
            "[47]\tvalidation_0-mlogloss:3.00700\n",
            "[48]\tvalidation_0-mlogloss:2.99193\n",
            "[49]\tvalidation_0-mlogloss:2.97758\n",
            "[50]\tvalidation_0-mlogloss:2.96343\n",
            "[51]\tvalidation_0-mlogloss:2.94921\n",
            "[52]\tvalidation_0-mlogloss:2.93542\n",
            "[53]\tvalidation_0-mlogloss:2.92174\n",
            "[54]\tvalidation_0-mlogloss:2.90830\n",
            "[55]\tvalidation_0-mlogloss:2.89506\n",
            "[56]\tvalidation_0-mlogloss:2.88212\n",
            "[57]\tvalidation_0-mlogloss:2.86939\n",
            "[58]\tvalidation_0-mlogloss:2.85653\n",
            "[59]\tvalidation_0-mlogloss:2.84389\n",
            "[60]\tvalidation_0-mlogloss:2.83165\n",
            "[61]\tvalidation_0-mlogloss:2.81941\n",
            "[62]\tvalidation_0-mlogloss:2.80751\n",
            "[63]\tvalidation_0-mlogloss:2.79529\n",
            "[64]\tvalidation_0-mlogloss:2.78337\n",
            "[65]\tvalidation_0-mlogloss:2.77162\n",
            "[66]\tvalidation_0-mlogloss:2.75976\n",
            "[67]\tvalidation_0-mlogloss:2.74825\n",
            "[68]\tvalidation_0-mlogloss:2.73699\n",
            "[69]\tvalidation_0-mlogloss:2.72552\n",
            "[70]\tvalidation_0-mlogloss:2.71423\n",
            "[71]\tvalidation_0-mlogloss:2.70321\n",
            "[72]\tvalidation_0-mlogloss:2.69238\n",
            "[73]\tvalidation_0-mlogloss:2.68172\n",
            "[74]\tvalidation_0-mlogloss:2.67092\n",
            "[75]\tvalidation_0-mlogloss:2.66038\n",
            "[76]\tvalidation_0-mlogloss:2.65017\n",
            "[77]\tvalidation_0-mlogloss:2.64001\n",
            "[78]\tvalidation_0-mlogloss:2.62959\n",
            "[79]\tvalidation_0-mlogloss:2.61966\n",
            "[80]\tvalidation_0-mlogloss:2.60975\n",
            "[81]\tvalidation_0-mlogloss:2.60000\n",
            "[82]\tvalidation_0-mlogloss:2.59018\n",
            "[83]\tvalidation_0-mlogloss:2.58071\n",
            "[84]\tvalidation_0-mlogloss:2.57094\n",
            "[85]\tvalidation_0-mlogloss:2.56134\n",
            "[86]\tvalidation_0-mlogloss:2.55205\n",
            "[87]\tvalidation_0-mlogloss:2.54274\n",
            "[88]\tvalidation_0-mlogloss:2.53369\n",
            "[89]\tvalidation_0-mlogloss:2.52464\n",
            "[90]\tvalidation_0-mlogloss:2.51551\n",
            "[91]\tvalidation_0-mlogloss:2.50649\n",
            "[92]\tvalidation_0-mlogloss:2.49762\n",
            "[93]\tvalidation_0-mlogloss:2.48888\n",
            "[94]\tvalidation_0-mlogloss:2.48004\n",
            "[95]\tvalidation_0-mlogloss:2.47148\n",
            "[96]\tvalidation_0-mlogloss:2.46274\n",
            "[97]\tvalidation_0-mlogloss:2.45452\n",
            "[98]\tvalidation_0-mlogloss:2.44580\n",
            "[99]\tvalidation_0-mlogloss:2.43759\n",
            "[100]\tvalidation_0-mlogloss:2.42922\n",
            "[101]\tvalidation_0-mlogloss:2.42123\n",
            "[102]\tvalidation_0-mlogloss:2.41312\n",
            "[103]\tvalidation_0-mlogloss:2.40497\n",
            "[104]\tvalidation_0-mlogloss:2.39677\n",
            "[105]\tvalidation_0-mlogloss:2.38899\n",
            "[106]\tvalidation_0-mlogloss:2.38101\n",
            "[107]\tvalidation_0-mlogloss:2.37342\n",
            "[108]\tvalidation_0-mlogloss:2.36538\n",
            "[109]\tvalidation_0-mlogloss:2.35772\n",
            "[110]\tvalidation_0-mlogloss:2.35029\n",
            "[111]\tvalidation_0-mlogloss:2.34281\n",
            "[112]\tvalidation_0-mlogloss:2.33542\n",
            "[113]\tvalidation_0-mlogloss:2.32792\n",
            "[114]\tvalidation_0-mlogloss:2.32049\n",
            "[115]\tvalidation_0-mlogloss:2.31342\n",
            "[116]\tvalidation_0-mlogloss:2.30620\n",
            "[117]\tvalidation_0-mlogloss:2.29902\n",
            "[118]\tvalidation_0-mlogloss:2.29199\n",
            "[119]\tvalidation_0-mlogloss:2.28481\n",
            "[120]\tvalidation_0-mlogloss:2.27796\n",
            "[121]\tvalidation_0-mlogloss:2.27095\n",
            "[122]\tvalidation_0-mlogloss:2.26427\n",
            "[123]\tvalidation_0-mlogloss:2.25738\n",
            "[124]\tvalidation_0-mlogloss:2.25081\n",
            "[125]\tvalidation_0-mlogloss:2.24413\n",
            "[126]\tvalidation_0-mlogloss:2.23738\n",
            "[127]\tvalidation_0-mlogloss:2.23099\n",
            "[128]\tvalidation_0-mlogloss:2.22444\n",
            "[129]\tvalidation_0-mlogloss:2.21789\n",
            "[130]\tvalidation_0-mlogloss:2.21140\n",
            "[131]\tvalidation_0-mlogloss:2.20514\n",
            "[132]\tvalidation_0-mlogloss:2.19873\n",
            "[133]\tvalidation_0-mlogloss:2.19230\n",
            "[134]\tvalidation_0-mlogloss:2.18618\n",
            "[135]\tvalidation_0-mlogloss:2.17999\n",
            "[136]\tvalidation_0-mlogloss:2.17393\n",
            "[137]\tvalidation_0-mlogloss:2.16774\n",
            "[138]\tvalidation_0-mlogloss:2.16175\n",
            "[139]\tvalidation_0-mlogloss:2.15579\n",
            "[140]\tvalidation_0-mlogloss:2.14973\n",
            "[141]\tvalidation_0-mlogloss:2.14370\n",
            "[142]\tvalidation_0-mlogloss:2.13791\n",
            "[143]\tvalidation_0-mlogloss:2.13202\n",
            "[144]\tvalidation_0-mlogloss:2.12610\n",
            "[145]\tvalidation_0-mlogloss:2.12021\n",
            "[146]\tvalidation_0-mlogloss:2.11440\n",
            "[147]\tvalidation_0-mlogloss:2.10883\n",
            "[148]\tvalidation_0-mlogloss:2.10319\n",
            "[149]\tvalidation_0-mlogloss:2.09748\n",
            "[150]\tvalidation_0-mlogloss:2.09187\n",
            "[151]\tvalidation_0-mlogloss:2.08637\n",
            "[152]\tvalidation_0-mlogloss:2.08068\n",
            "[153]\tvalidation_0-mlogloss:2.07524\n",
            "[154]\tvalidation_0-mlogloss:2.06978\n",
            "[155]\tvalidation_0-mlogloss:2.06428\n",
            "[156]\tvalidation_0-mlogloss:2.05887\n",
            "[157]\tvalidation_0-mlogloss:2.05356\n",
            "[158]\tvalidation_0-mlogloss:2.04828\n",
            "[159]\tvalidation_0-mlogloss:2.04294\n",
            "[160]\tvalidation_0-mlogloss:2.03750\n",
            "[161]\tvalidation_0-mlogloss:2.03238\n",
            "[162]\tvalidation_0-mlogloss:2.02724\n",
            "[163]\tvalidation_0-mlogloss:2.02203\n",
            "[164]\tvalidation_0-mlogloss:2.01675\n",
            "[165]\tvalidation_0-mlogloss:2.01181\n",
            "[166]\tvalidation_0-mlogloss:2.00666\n",
            "[167]\tvalidation_0-mlogloss:2.00179\n",
            "[168]\tvalidation_0-mlogloss:1.99671\n",
            "[169]\tvalidation_0-mlogloss:1.99163\n",
            "[170]\tvalidation_0-mlogloss:1.98669\n",
            "[171]\tvalidation_0-mlogloss:1.98191\n",
            "[172]\tvalidation_0-mlogloss:1.97704\n",
            "[173]\tvalidation_0-mlogloss:1.97212\n",
            "[174]\tvalidation_0-mlogloss:1.96733\n",
            "[175]\tvalidation_0-mlogloss:1.96259\n",
            "[176]\tvalidation_0-mlogloss:1.95796\n",
            "[177]\tvalidation_0-mlogloss:1.95328\n",
            "[178]\tvalidation_0-mlogloss:1.94852\n",
            "[179]\tvalidation_0-mlogloss:1.94383\n",
            "[180]\tvalidation_0-mlogloss:1.93908\n",
            "[181]\tvalidation_0-mlogloss:1.93463\n",
            "[182]\tvalidation_0-mlogloss:1.93000\n",
            "[183]\tvalidation_0-mlogloss:1.92547\n",
            "[184]\tvalidation_0-mlogloss:1.92090\n",
            "[185]\tvalidation_0-mlogloss:1.91633\n",
            "[186]\tvalidation_0-mlogloss:1.91193\n",
            "[187]\tvalidation_0-mlogloss:1.90758\n",
            "[188]\tvalidation_0-mlogloss:1.90322\n",
            "[189]\tvalidation_0-mlogloss:1.89888\n",
            "[190]\tvalidation_0-mlogloss:1.89454\n",
            "[191]\tvalidation_0-mlogloss:1.89019\n",
            "[192]\tvalidation_0-mlogloss:1.88575\n",
            "[193]\tvalidation_0-mlogloss:1.88156\n",
            "[194]\tvalidation_0-mlogloss:1.87721\n",
            "[195]\tvalidation_0-mlogloss:1.87303\n",
            "[196]\tvalidation_0-mlogloss:1.86890\n",
            "[197]\tvalidation_0-mlogloss:1.86463\n",
            "[198]\tvalidation_0-mlogloss:1.86047\n",
            "[199]\tvalidation_0-mlogloss:1.85637\n",
            "\n",
            "Training complete!\n",
            "   Training time: 173.71 minutes (10422.6 seconds)\n",
            "   Number of trees: 200\n",
            "   Max depth: 8\n",
            "   Trained on: 153,489 samples (X_train only)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING XGBOOST MODEL (UNWEIGHTED)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Create XGBoost classifier\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=86,\n",
        "    max_depth=config['max_depth'],\n",
        "    learning_rate=config['learning_rate'],\n",
        "    n_estimators=config['n_estimators'],\n",
        "    tree_method=config['tree_method'],\n",
        "    device=config['device'],\n",
        "    random_state=config['random_state'],\n",
        "    n_jobs=config['n_jobs'],\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining configuration:\")\n",
        "print(f\"   Training on: X_train only ({len(X_train):,} samples)\")\n",
        "print(f\"   Monitoring on: X_val ({len(X_val):,} samples) - for progress tracking only\")\n",
        "print(f\"   Final evaluation: X_test ({len(X_test):,} samples)\")\n",
        "print(f\"   Sample weighting: None (unweighted training)\")\n",
        "\n",
        "print(f\"\\nStarting training with {config['n_estimators']} trees...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Train WITHOUT sample weights - validation used for monitoring only\n",
        "xgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],  # Validation for monitoring only, NOT for training\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nTraining complete!\")\n",
        "print(f\"   Training time: {train_time/60:.2f} minutes ({train_time:.1f} seconds)\")\n",
        "print(f\"   Number of trees: {xgb_model.n_estimators}\")\n",
        "print(f\"   Max depth: {xgb_model.max_depth}\")\n",
        "print(f\"   Trained on: {len(X_train):,} samples (X_train only)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-BHOlY595ck"
      },
      "source": [
        "System RAM\n",
        "11.2 / 12.7 GB\n",
        "\n",
        "**this from side window of google colab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval_val"
      },
      "source": [
        "## 7. Evaluate on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "val_eval",
        "outputId": "7cf206e1-f168-43d6-851b-3e2f17901807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TEST SET EVALUATION - FINAL RESULTS\n",
            "================================================================================\n",
            "\n",
            "üîç Making predictions on test set...\n",
            "\n",
            "================================================================================\n",
            "üéØ XGBOOST - FINAL TEST RESULTS (Use for GNN Comparison)\n",
            "================================================================================\n",
            "\n",
            "üìä ACCURACY METRICS:\n",
            "   Top-1 Accuracy:          0.6955\n",
            "   Top-3 Accuracy:          0.9224\n",
            "\n",
            "üìä F1-SCORE:\n",
            "   F1-Macro:                0.5497\n",
            "   F1-Weighted:             0.6791\n",
            "\n",
            "üìä PRECISION:\n",
            "   Precision-Macro:         0.6665\n",
            "   Precision-Weighted:      0.7307\n",
            "\n",
            "üìä RECALL:\n",
            "   Recall-Macro:            0.5076\n",
            "   Recall-Weighted:         0.6955\n",
            "\n",
            "üìä ROC-AUC:\n",
            "   ROC-AUC-Macro:           0.9709\n",
            "   ROC-AUC-Weighted:        0.9457\n",
            "\n",
            "‚è±Ô∏è  PERFORMANCE:\n",
            "   Prediction time:         21.98 seconds\n",
            "   Test samples:            19,200\n",
            "\n",
            "================================================================================\n",
            "‚úÖ These are the final metrics for comparing with your GNN model\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# TEST SET EVALUATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEST SET EVALUATION - FINAL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüîç Making predictions on test set...\")\n",
        "test_start = time.time()\n",
        "\n",
        "# Get predictions and probabilities\n",
        "y_test_pred = xgb_model.predict(X_test)\n",
        "y_test_proba = xgb_model.predict_proba(X_test)  # For ROC-AUC and Top-K\n",
        "\n",
        "test_time = time.time() - test_start\n",
        "\n",
        "# ============================================================================\n",
        "# STANDARD METRICS (Macro & Weighted)\n",
        "# ============================================================================\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "test_f1_macro = f1_score(y_test, y_test_pred, average='macro')\n",
        "test_f1_weighted = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "test_precision_macro = precision_score(y_test, y_test_pred, average='macro')\n",
        "test_precision_weighted = precision_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "test_recall_macro = recall_score(y_test, y_test_pred, average='macro')\n",
        "test_recall_weighted = recall_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "# ============================================================================\n",
        "# ROC-AUC (One-vs-Rest)\n",
        "# ============================================================================\n",
        "from sklearn.metrics import roc_auc_score\n",
        "test_roc_auc_macro = roc_auc_score(y_test, y_test_proba, average='macro', multi_class='ovr')\n",
        "test_roc_auc_weighted = roc_auc_score(y_test, y_test_proba, average='weighted', multi_class='ovr')\n",
        "\n",
        "# ============================================================================\n",
        "# TOP-K ACCURACY\n",
        "# ============================================================================\n",
        "def top_k_accuracy(y_true, y_proba, k):\n",
        "    \"\"\"Calculate top-k accuracy\"\"\"\n",
        "    top_k_preds = np.argsort(y_proba, axis=1)[:, -k:]  # Get top-k predictions\n",
        "    correct = np.array([y_true[i] in top_k_preds[i] for i in range(len(y_true))])\n",
        "    return np.mean(correct)\n",
        "\n",
        "top1_accuracy = top_k_accuracy(y_test, y_test_proba, k=1)  # Same as regular accuracy\n",
        "top3_accuracy = top_k_accuracy(y_test, y_test_proba, k=3)\n",
        "\n",
        "# ============================================================================\n",
        "# DISPLAY RESULTS\n",
        "# ============================================================================\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ XGBOOST - FINAL TEST RESULTS (Use for GNN Comparison)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nüìä ACCURACY METRICS:\")\n",
        "print(f\"   Top-1 Accuracy:          {test_accuracy:.4f}\")\n",
        "print(f\"   Top-3 Accuracy:          {top3_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nüìä F1-SCORE:\")\n",
        "print(f\"   F1-Macro:                {test_f1_macro:.4f}\")\n",
        "print(f\"   F1-Weighted:             {test_f1_weighted:.4f}\")\n",
        "\n",
        "print(f\"\\nüìä PRECISION:\")\n",
        "print(f\"   Precision-Macro:         {test_precision_macro:.4f}\")\n",
        "print(f\"   Precision-Weighted:      {test_precision_weighted:.4f}\")\n",
        "\n",
        "print(f\"\\nüìä RECALL:\")\n",
        "print(f\"   Recall-Macro:            {test_recall_macro:.4f}\")\n",
        "print(f\"   Recall-Weighted:         {test_recall_weighted:.4f}\")\n",
        "\n",
        "print(f\"\\nüìä ROC-AUC:\")\n",
        "print(f\"   ROC-AUC-Macro:           {test_roc_auc_macro:.4f}\")\n",
        "print(f\"   ROC-AUC-Weighted:        {test_roc_auc_weighted:.4f}\")\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è  PERFORMANCE:\")\n",
        "print(f\"   Prediction time:         {test_time:.2f} seconds\")\n",
        "print(f\"   Test samples:            {len(X_test):,}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(f\"‚úÖ These are the final metrics for comparing with our GNN model\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval_test"
      },
      "source": [
        "## 8. Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK61kj8HReCA",
        "outputId": "043e26f6-a88e-46ea-ee98-2a0850d5bfab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TEST SET EVALUATION\n",
            "================================================================================\n",
            "\n",
            "üîç Making predictions on test set...\n",
            "\n",
            "================================================================================\n",
            "XGBOOST - FINAL TEST RESULTS\n",
            "================================================================================\n",
            "\n",
            "üìä Test Set Performance:\n",
            "   Accuracy:     0.6955\n",
            "   Precision:    0.6955\n",
            "   Recall:       0.6955\n",
            "   F1-Micro:     0.6955\n",
            "   F1-Macro:     0.5497\n",
            "\n",
            "‚è±Ô∏è  Timing:\n",
            "   Training time:    173.71 minutes\n",
            "   Inference time:   10.82 seconds\n",
            "   Speed: 1774.2 predictions/sec\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# TEST SET EVALUATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüîç Making predictions on test set...\")\n",
        "test_start = time.time()\n",
        "y_test_pred = xgb_model.predict(X_test)\n",
        "test_time = time.time() - test_start\n",
        "\n",
        "# Calculate all metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1_micro = f1_score(y_test, y_test_pred, average='micro')\n",
        "test_f1_macro = f1_score(y_test, y_test_pred, average='macro')\n",
        "test_precision = precision_score(y_test, y_test_pred, average='micro')\n",
        "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"XGBOOST - FINAL TEST RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä Test Set Performance:\")\n",
        "print(f\"   Accuracy:     {test_accuracy:.4f}\")\n",
        "print(f\"   Precision:    {test_precision:.4f}\")\n",
        "print(f\"   Recall:       {test_recall:.4f}\")\n",
        "print(f\"   F1-Micro:     {test_f1_micro:.4f}\")\n",
        "print(f\"   F1-Macro:     {test_f1_macro:.4f}\")\n",
        "print(f\"\\n‚è±Ô∏è  Timing:\")\n",
        "print(f\"   Training time:    {train_time/60:.2f} minutes\")\n",
        "print(f\"   Inference time:   {test_time:.2f} seconds\")\n",
        "print(f\"   Speed: {len(y_test)/test_time:.1f} predictions/sec\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analysis"
      },
      "source": [
        "## 9. Detailed Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "analysis_detail",
        "outputId": "fef56a83-eea6-4e0e-fa25-940e879d3643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PER-CLASS PERFORMANCE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Top 5 Best Performing Classes:\n",
            "   1. Class 6: F1=1.0000, Precision=1.0000, Recall=1.0000 (1 samples)\n",
            "   2. Class 0: F1=1.0000, Precision=1.0000, Recall=1.0000 (2 samples)\n",
            "   3. Class 44: F1=1.0000, Precision=1.0000, Recall=1.0000 (2 samples)\n",
            "   4. Class 42: F1=1.0000, Precision=1.0000, Recall=1.0000 (1 samples)\n",
            "   5. Class 37: F1=1.0000, Precision=1.0000, Recall=1.0000 (2 samples)\n",
            "\n",
            "Bottom 5 Worst Performing Classes:\n",
            "   1. Class 25: F1=0.0000, Precision=0.0000, Recall=0.0000 (1 samples)\n",
            "   2. Class 27: F1=0.0000, Precision=0.0000, Recall=0.0000 (1 samples)\n",
            "   3. Class 43: F1=0.0000, Precision=0.0000, Recall=0.0000 (2 samples)\n",
            "   4. Class 41: F1=0.0000, Precision=0.0000, Recall=0.0000 (1 samples)\n",
            "   5. Class 51: F1=0.0000, Precision=0.0000, Recall=0.0000 (1 samples)\n",
            "\n",
            "Overall Statistics:\n",
            "   Mean F1 across classes: 0.6429\n",
            "   Std F1 across classes: 0.2562\n",
            "   Classes with F1 > 0.8: 25/86\n",
            "   Classes with F1 < 0.5: 16/86\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PER-CLASS PERFORMANCE ANALYSIS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PER-CLASS PERFORMANCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate per-class metrics\n",
        "per_class_f1 = f1_score(y_test, y_test_pred, average=None)\n",
        "per_class_precision = precision_score(y_test, y_test_pred, average=None, zero_division=0)\n",
        "per_class_recall = recall_score(y_test, y_test_pred, average=None, zero_division=0)\n",
        "\n",
        "# Find best and worst performing classes\n",
        "best_classes = np.argsort(per_class_f1)[-5:][::-1]\n",
        "worst_classes = np.argsort(per_class_f1)[:5]\n",
        "\n",
        "print(f\"\\nTop 5 Best Performing Classes:\")\n",
        "for i, class_idx in enumerate(best_classes, 1):\n",
        "    test_samples = (y_test == class_idx).sum()\n",
        "    print(f\"   {i}. Class {class_idx}: F1={per_class_f1[class_idx]:.4f}, \"\n",
        "          f\"Precision={per_class_precision[class_idx]:.4f}, \"\n",
        "          f\"Recall={per_class_recall[class_idx]:.4f} ({test_samples} samples)\")\n",
        "\n",
        "print(f\"\\nBottom 5 Worst Performing Classes:\")\n",
        "for i, class_idx in enumerate(worst_classes, 1):\n",
        "    test_samples = (y_test == class_idx).sum()\n",
        "    print(f\"   {i}. Class {class_idx}: F1={per_class_f1[class_idx]:.4f}, \"\n",
        "          f\"Precision={per_class_precision[class_idx]:.4f}, \"\n",
        "          f\"Recall={per_class_recall[class_idx]:.4f} ({test_samples} samples)\")\n",
        "\n",
        "print(f\"\\nOverall Statistics:\")\n",
        "print(f\"   Mean F1 across classes: {per_class_f1.mean():.4f}\")\n",
        "print(f\"   Std F1 across classes: {per_class_f1.std():.4f}\")\n",
        "print(f\"   Classes with F1 > 0.8: {(per_class_f1 > 0.8).sum()}/86\")\n",
        "print(f\"   Classes with F1 < 0.5: {(per_class_f1 < 0.5).sum()}/86\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save"
      },
      "source": [
        "## 10. Save Model & Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "save_results",
        "outputId": "23d6242b-1125-4735-f19b-7fcd4ad8a97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SAVING MODEL AND RESULTS\n",
            "================================================================================\n",
            "‚úÖ Model saved to: /content/drive/MyDrive/XGBoost/xgboost_model.json\n",
            "‚úÖ Results saved to: /content/drive/MyDrive/XGBoost/xgboost_results.pkl\n",
            "‚úÖ Summary saved to: /content/drive/MyDrive/XGBoost/xgboost_summary.csv\n",
            "\n",
            "================================================================================\n",
            "ALL DONE! ‚ú®\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SAVE MODEL AND RESULTS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAVING MODEL AND RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save XGBoost model\n",
        "model_path = f'{BASE_PATH}xgboost_model.json'\n",
        "xgb_model.save_model(model_path)\n",
        "print(f\"‚úÖ Model saved to: {model_path}\")\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'config': config,\n",
        "    'train_time_minutes': train_time / 60,\n",
        "    'test_time_seconds': test_time,\n",
        "    'validation_metrics': {\n",
        "        'accuracy': val_accuracy,\n",
        "        'f1_micro': val_f1_micro,\n",
        "        'f1_macro': val_f1_macro,\n",
        "        'precision': val_precision,\n",
        "        'recall': val_recall\n",
        "    },\n",
        "    'test_metrics': {\n",
        "        'accuracy': test_accuracy,\n",
        "        'f1_micro': test_f1_micro,\n",
        "        'f1_macro': test_f1_macro,\n",
        "        'precision': test_precision,\n",
        "        'recall': test_recall\n",
        "    },\n",
        "    'per_class_f1': per_class_f1.tolist(),\n",
        "    'class_weights': class_weights.tolist(),\n",
        "    'predictions': {\n",
        "        'y_test_true': y_test.tolist(),\n",
        "        'y_test_pred': y_test_pred.tolist()\n",
        "    }\n",
        "}\n",
        "\n",
        "results_path = f'{BASE_PATH}xgboost_results.pkl'\n",
        "with open(results_path, 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "print(f\"‚úÖ Results saved to: {results_path}\")\n",
        "\n",
        "# Save summary as CSV\n",
        "summary_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Micro', 'F1-Macro'],\n",
        "    'Validation': [val_accuracy, val_precision, val_recall, val_f1_micro, val_f1_macro],\n",
        "    'Test': [test_accuracy, test_precision, test_recall, test_f1_micro, test_f1_macro]\n",
        "})\n",
        "\n",
        "summary_path = f'{BASE_PATH}xgboost_summary.csv'\n",
        "summary_df.to_csv(summary_path, index=False)\n",
        "print(f\"‚úÖ Summary saved to: {summary_path}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"ALL DONE! ‚ú®\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
